{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import scipy.misc\n",
    "from easydict import EasyDict as edict\n",
    "from models.IDN_YCbCr import *\n",
    "from utils import *\n",
    "from ops import *\n",
    "from dataloader import *\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = edict()\n",
    "# training parameters\n",
    "config.batch_size = 64\n",
    "config.patch_size = 17 # patch size in LR domain (in HR domain it should be multiplied by scale)\n",
    "config.mode = \"YCbCr\" #YCbCr\n",
    "config.channels = 1\n",
    "#config.mode = \"RGB\" #YCbCr\n",
    "#config.channels = 3\n",
    "config.scale = 3\n",
    "config.content_layer = 'relu5_4'\n",
    "config.learning_rate = 1e-4\n",
    "config.augmentation = True #data augmentation (flip, rotation)\n",
    "\n",
    "config.epochs = 500\n",
    "config.test_every = 1\n",
    "config.repeat = 100\n",
    "\n",
    "config.num_d_blocks = 4\n",
    "\n",
    "# weights for loss \n",
    "config.w_losses = {'L1':1, 'MSE':0, 'texture': 0, 'content': 0, 'tv':0}\n",
    "\n",
    "config.model_name = \"IDN-YbCr\"\n",
    "\n",
    "# directories\n",
    "config.dataset_name = \"DIV2K\"\n",
    "config.testset_name = \"Set5\"#\"Set5\"\n",
    "config.train_path_LR = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/train/\",\"%s_LR/*.png\" %str(config.dataset_name))\n",
    "config.train_path_HR = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/train/\",str(config.dataset_name),\"*.png\")\n",
    "config.valid_path_HR = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/vaild/\",str(config.dataset_name),\"*.png\")\n",
    "#config.test_path = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/test/\",str(config.testset_name),\"*.png\")\n",
    "\n",
    "config.test_path_HR = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/test/%s/HR/*.png\" %str(config.testset_name))\n",
    "config.test_path_LR = os.path.join(\"/home/johnyi/deeplearning/research/SISR_Datasets/test/%s/LR/*.png\" %str(config.testset_name))\n",
    "config.vgg_dir = \"../vgg_pretrained/imagenet-vgg-verydeep-19.mat\"\n",
    "\n",
    "config.result_dir = os.path.join(\"./result\", config.model_name, \"D%d\" %config.num_d_blocks)\n",
    "config.result_img_dir = os.path.join(config.result_dir, \"images\", config.testset_name)\n",
    "config.checkpoint_dir = os.path.join(config.result_dir, \"model\")\n",
    "\n",
    "if not os.path.exists(config.checkpoint_dir):\n",
    "    print(\"creating dir...\", config.checkpoint_dir)\n",
    "    os.makedirs(config.checkpoint_dir)\n",
    "if not os.path.exists(config.result_dir):\n",
    "    print(\"creating dir...\", config.result_dir)\n",
    "    os.makedirs(config.result_dir)\n",
    "if not os.path.exists(config.result_img_dir):\n",
    "    print(\"creating dir...\", config.result_img_dir)\n",
    "    os.makedirs(config.result_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO list\n",
    "1. data loader 확인 -> OK\n",
    "2. GAN 빼고 PSNR로만 training -> 되는 것 같은데 PSNR이 낮음\n",
    "3. discriminator pretrain해서 잘 되는지 확인\n",
    "4. 전체 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: DIV2K, 900 images\n",
      "loading 900 LR images...\n",
      "loading 900 HR images...\n",
      "900 image pairs loaded! setting took: 99.0924s\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset_LR, dataset_HR = load_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17, 1)\n"
     ]
    }
   ],
   "source": [
    "LR_batch, HR_batch, bicubic_batch = get_batch_Y(dataset_LR, dataset_HR, 200, config)\n",
    "print(LR_batch[0].shape)\n",
    "x = 197\n",
    "imageio.imwrite(\"LR.png\", postprocess_Y(LR_batch[x]))\n",
    "imageio.imwrite(\"HR.png\", postprocess_Y(HR_batch[x]))\n",
    "imageio.imwrite(\"bicubic.png\", postprocess_Y(bicubic_batch[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating IDN YCbCrx3\n",
      "Completed building generator. Number of variables: 62\n",
      "creating L1 loss, weight:  1\n",
      "Content loss not available in YCbCr space\n",
      "no texture loss\n",
      "no tv loss\n",
      "no color (MSE) loss\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "tf.reset_default_graph()\n",
    "# uncomment this when only trying to test the model\n",
    "dataset_LR = []\n",
    "dataset_HR = []\n",
    "sess = tf.Session()\n",
    "model = IDN_YCbCr(sess, config, dataset_LR, dataset_HR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Discriminator training starts from beginning\n",
      "------Iteration 0, runtime: 0.241 s, discriminator loss: 1.386617\n",
      "Discriminator test accuracy: bicubic: 0/200, HR: 200/200\n",
      "------Iteration 1000, runtime: 103.803 s, discriminator loss: 0.871274\n",
      "Discriminator test accuracy: bicubic: 200/200, HR: 141/200\n",
      "------Iteration 2000, runtime: 207.872 s, discriminator loss: 0.518489\n",
      "Discriminator test accuracy: bicubic: 179/200, HR: 182/200\n",
      "------Iteration 3000, runtime: 311.988 s, discriminator loss: 0.463568\n",
      "Discriminator test accuracy: bicubic: 199/200, HR: 160/200\n",
      "------Iteration 4000, runtime: 416.192 s, discriminator loss: 0.807680\n",
      "Discriminator test accuracy: bicubic: 180/200, HR: 176/200\n",
      "pretraining complete\n"
     ]
    }
   ],
   "source": [
    "# pretrain discriminator with (phone, dslr) pairs\n",
    "model.pretrain_discriminator(load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator-pretrained\n",
      "Loading checkpoints from  checkpoint/DIV2K\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/DIV2K/Discriminator-pretrained\n",
      " [*] Load SUCCESS\n",
      "Discriminator test accuracy: bicubic: 176/200, HR: 97/200\n"
     ]
    }
   ],
   "source": [
    "# test discriminator performance for (phone, dslr) pair\n",
    "model.test_discriminator(200, load = True, model_name = \"LPSR-YCbCr-discriminator-pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./result/IDN-YbCr/D4/model/model_best\n",
      "Continuing from epoch 12\n",
      "Number of images: 900, batch size: 64, num_repeat: 100 --> each epoch consists of 1406 iterations\n",
      "------Epoch 13, runtime: 90.787 s, generator loss: 3.524018\n",
      "image size:  (510, 510, 1) , inference time: 0.040386199951171875\n",
      "image size:  (288, 288, 1) , inference time: 0.004417896270751953\n",
      "image size:  (255, 255, 1) , inference time: 0.003637552261352539\n",
      "image size:  (279, 279, 1) , inference time: 0.00420379638671875\n",
      "image size:  (342, 228, 1) , inference time: 0.004185676574707031\n",
      "Test PSNR: 34.016 (best: 34.046 at epoch 9), bicubic: 30.403\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-58c999e3fd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train generator & discriminator together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deeplearning/research/jhyi16-TensorFlow-SR/models/IDN_YCbCr.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, load)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_HR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_HR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mLR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicubic_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_LR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_HR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menhanced_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexture_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtv_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhanced_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexture_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtv_loss\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLR_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHR_patch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mHR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbicubic_patch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbicubic_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/research/jhyi16-TensorFlow-SR/dataloader.py\u001b[0m in \u001b[0;36mget_batch_Y\u001b[0;34m(dataset_LR, dataset_HR, num, config, start)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mLR_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pre/post processing function is defined in ops.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mHR_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHR_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mbicubic_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbicubic_patch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHR_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicubic_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/research/jhyi16-TensorFlow-SR/utils.py\u001b[0m in \u001b[0;36mget_Y\u001b[0;34m(frame)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#frame_ycbcr = cv2.cvtColor(frame, cv2.COLOR_RGB2YCrCb) # This returns Y in [0, 255]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"uint8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mframe_ycbcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb2ycbcr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This returns Y in [16, 235]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#print(np.max(frame_ycbcr[:,:,0]), np.min(frame_ycbcr[:,:,0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_ycbcr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2ycbcr\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m   1697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1698\u001b[0m     \"\"\"\n\u001b[0;32m-> 1699\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mycbcr_from_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1700\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(matrix, arr)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train generator & discriminator together\n",
    "model.train(load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./result/IDN-YbCr/D4/model/model_best\n",
      "Continuing from epoch 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37.440325387601405, 34.91064951925091)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test trained model\n",
    "model.test_generator(load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoints from  ./result/IDN-YbCr/D4/model/model_latest\n",
      "INFO:tensorflow:Restoring parameters from ./result/IDN-YbCr/D4/model/model_latest\n",
      "Continuing from epoch 1\n",
      "3.227469512460727685e+01\n"
     ]
    }
   ],
   "source": [
    "model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[117.00709412 121.25263137 132.00306667]]]\n",
      "[[[117.37863    4.992876  -7.079951]]]\n"
     ]
    }
   ],
   "source": [
    "import skimage.color as sc\n",
    "import cv2\n",
    "mean_RGB = np.zeros([1,1,3], dtype = \"uint8\")\n",
    "mean_RGB[:,:,:] = [124 ,  117,  104] #np.array([123.68 ,  116.779,  103.939])\n",
    "mean_ycbcr = sc.rgb2ycbcr(mean_RGB)\n",
    "print(mean_ycbcr)\n",
    "mean_RGB2 = np.zeros([1,1,3], dtype = \"float32\")\n",
    "mean_RGB2[:,:,:] = [123.68 ,  116.779,  103.939]\n",
    "mean_ycbcr2 = cv2.cvtColor(mean_RGB2, cv2.COLOR_RGB2YCrCb)\n",
    "print(mean_ycbcr2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
