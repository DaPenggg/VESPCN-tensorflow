{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from VESPCN_utils import *\n",
    "from warp import *\n",
    "import tensorflow as tf\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "config = edict()\n",
    "\n",
    "config.sample_dir = \"samples_MCT\"\n",
    "config.checkpoint_dir = \"checkpoint/MCT\"\n",
    "config.log_dir = \"logs\"\n",
    "config.train_size = 100000000 # use large number if you have enough memory\n",
    "config.valid_size = 10 # use large number if you have enough memory\n",
    "config.test_size = 6400 # use large number if you have enough memory\n",
    "config.batch_size = 8 # use large number if you have enough memory\n",
    "config.patch_shape = [48,48,3] #[51,51,3]\n",
    "config.scale = 3 #3\n",
    "config.learning_rate = 1e-4\n",
    "config.epoch = 1000000\n",
    "config.channels = 3\n",
    "config.mode = \"RGB\"\n",
    "\n",
    "#config.channels = 1\n",
    "#config.mode = \"YCbCr\"\n",
    "\n",
    "#'''\n",
    "config.dataset = \"CDVL\"\n",
    "config.num_videos = 76\n",
    "\n",
    "#'''\n",
    "config.train = edict()\n",
    "config.train.lr_init = 1e-3\n",
    "config.train.lr_decay = 0.5\n",
    "config.train.decay_iter = 10\n",
    "config.augmentation = True\n",
    "\n",
    "if not os.path.exists(config.checkpoint_dir):\n",
    "    os.makedirs(config.checkpoint_dir)\n",
    "if not os.path.exists(config.sample_dir):\n",
    "    os.makedirs(config.sample_dir)\n",
    "if not os.path.exists(config.log_dir):\n",
    "    os.makedirs(config.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_MCT(imdb, num_frames_per_video, batch_size, patch_size, augmentation = False):\n",
    "    batch_t0 = np.zeros([batch_size, patch_size[0], patch_size[1], 3], dtype = 'uint8')\n",
    "    batch_t1 = np.zeros([batch_size, patch_size[0], patch_size[1], 3], dtype = 'uint8')\n",
    "    resize_ratio = 1\n",
    "    flags = np.zeros(len(num_frames_per_video))\n",
    "    for i in range(batch_size):\n",
    "        video_index = np.random.randint(len(num_frames_per_video)) #select random frame from video\n",
    "        while flags[video_index] == 1:\n",
    "            video_index = np.random.randint(len(num_frames_per_video)) #select random frame from video\n",
    "        flags[video_index] = 1\n",
    "        #video_index = 0\n",
    "        frame_num = np.random.randint(num_frames_per_video[video_index])\n",
    "        if augmentation == True:\n",
    "            resize_ratio = np.random.rand()*0.5 + 0.5\n",
    "        if frame_num == 0 or frame_num == num_frames_per_video[video_index] - 1:\n",
    "            t0 = imdb[video_index][frame_num, : ,: ,:]\n",
    "            t1 = imdb[video_index][frame_num, : ,: ,:]\n",
    "        else:\n",
    "            t0 = imdb[video_index][frame_num, : ,: ,:]\n",
    "            t1 = imdb[video_index][frame_num+1, : ,: ,:]\n",
    "        #print(t0.shape)\n",
    "        H = np.random.randint(t0.shape[0]-int(np.ceil(patch_size[0]/resize_ratio)))\n",
    "        W = np.random.randint(t0.shape[1]-int(np.ceil(patch_size[1]/resize_ratio)))\n",
    "        patch_t0 = t0[H:H+int(np.ceil(patch_size[0]/resize_ratio)), W:W+int(np.ceil(patch_size[1]/resize_ratio)),:]\n",
    "        patch_t0 = imresize(patch_t0, patch_size, interp = \"bicubic\")\n",
    "        patch_t1 = t1[H:H+int(np.ceil(patch_size[0]/resize_ratio)), W:W+int(np.ceil(patch_size[1]/resize_ratio)),:]\n",
    "        patch_t1 = imresize(patch_t1, patch_size, interp = \"bicubic\")\n",
    "        batch_t0[i,:,:,:] = patch_t0\n",
    "        batch_t1[i,:,:,:] = patch_t1\n",
    "    return batch_t0, batch_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "(1, 1000, 1000, 3) (1, 1000, 1000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "#imdb, num_frames_per_video = load_videos(10, 60, 50, \"RGB\")\n",
    "#print(imdb[0].shape)\n",
    "batch_t0, batch_t1 = get_batch_MCT(imdb, num_frames_per_video, 1, [1000, 1000], augmentation = False)\n",
    "print(batch_t0.shape, batch_t1.shape)\n",
    "imageio.imwrite(\"test_0.png\", np.squeeze(batch_t0[0,:,:,:]))\n",
    "imageio.imwrite(\"test_1.png\", np.squeeze(batch_t1[0,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "from subpixel import PS\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from VESPCN_utils import *\n",
    "from warp import *\n",
    "\n",
    "class MotionCompensationTransformer(object):\n",
    "    def __init__(self, sess, config):\n",
    "        self.sess = sess\n",
    "        self.config = config\n",
    "        self.batch_size = config.batch_size\n",
    "        self.valid_size = config.batch_size\n",
    "        self.patch_shape = config.patch_shape\n",
    "        self.input_size = int(config.patch_shape[0])\n",
    "        self.dataset_name = config.dataset\n",
    "        self.mode = config.mode\n",
    "        self.channels = config.channels\n",
    "        self.augmentation = config.augmentation\n",
    "        self.checkpoint_dir = config.checkpoint_dir\n",
    "        self.build_model()\n",
    "        tf.global_variables_initializer().run(session=self.sess)\n",
    "        #x = self.sess.run([self.output], feed_dict = {self.input_t0: np.zeros([8,48,48,self.channels]), self.input_t1: np.zeros([8,48,48,self.channels])})\n",
    "        #print(x[0].shape)\n",
    "        self.num_videos = config.num_videos\n",
    "\n",
    "    def build_model(self):\n",
    "        #input frames\n",
    "        self.input_t0 = tf.placeholder(tf.float32, [self.batch_size, self.input_size, self.input_size, self.channels], name='input_t0') \n",
    "        self.input_t1 = tf.placeholder(tf.float32, [self.batch_size, self.input_size, self.input_size, self.channels], name='input_t1') \n",
    "\n",
    "        #output frame (compensated t1)\n",
    "        self.output = self.network(self.input_t0, self.input_t1)\n",
    "        \n",
    "        #for unknown sizes\n",
    "        self.input2_t0 = tf.placeholder(tf.float32, [None, 576, 720, self.channels], name='input_t0_unkown')\n",
    "        self.input2_t1 = tf.placeholder(tf.float32, [None, 576, 720, self.channels], name='input_t1_unkown')\n",
    "        self.output2 = self.network(self.input2_t0, self.input2_t1)\n",
    "\n",
    "        self.loss = tf.reduce_mean(tf.square(self.input_t0-self.output)) + \\\n",
    "                0.01 * tf.reduce_mean(tf.sqrt(tf.add(tf.square(self.input_t0-self.output),1e-4))) #approximated Huber loss\n",
    "        self.vars = tf.trainable_variables()\n",
    "        print(\"Number of variables in network:\",len(self.vars),\", full list:\",self.vars)\n",
    "        self.optimizer = tf.train.AdamOptimizer(self.config.learning_rate).minimize(self.loss, var_list=self.vars)\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "    def network(self, t0, t1):\n",
    "        ######## coasrse flow ######\n",
    "        tmp = tf.concat([t0, t1], axis = 3) #early fusion\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 5, strides = 2, padding = 'SAME', name = 'Coarse_1', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 3, strides = 1, padding = 'SAME', name = 'Coarse_2', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 5, strides = 2, padding = 'SAME', name = 'Coarse_3', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 3, strides = 1, padding = 'SAME', name = 'Coarse_4', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 32, 3, strides = 1, padding = 'SAME', name = 'Coarse_5', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.tanh(tmp)\n",
    "\n",
    "        coarse_x = tf.layers.conv2d(tmp, 4*4*1, 3, strides = 1, padding = 'SAME', name = 'Coarse_x', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        coarse_y = tf.layers.conv2d(tmp, 4*4*1, 3, strides = 1, padding = 'SAME', name = 'Coarse_y', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        coarse_x = PS(coarse_x, 4, color=False)\n",
    "        coarse_y = PS(coarse_y, 4, color=False)\n",
    "        #print(\"shape: \", coarse_x.shape, coarse_y.shape)\n",
    "        \n",
    "        ######## fine flow ######\n",
    "        tmp = tf.concat([t0, t1], axis = 3) #early fusion\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 5, strides = 2, padding = 'SAME', name = 'Fine_1', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 3, strides = 1, padding = 'SAME', name = 'Fine_2', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 3, strides = 1, padding = 'SAME', name = 'Fine_3', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 24, 3, strides = 1, padding = 'SAME', name = 'Fine_4', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.relu(tmp)\n",
    "        tmp = tf.layers.conv2d(tmp, 8, 3, strides = 1, padding = 'SAME', name = 'Fine_5', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        tmp = tf.nn.tanh(tmp)\n",
    "\n",
    "        fine_x = tf.layers.conv2d(tmp, 2*2*1, 3, strides = 1, padding = 'SAME', name = 'Fine_x', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        fine_y = tf.layers.conv2d(tmp, 2*2*1, 3, strides = 1, padding = 'SAME', name = 'Fine_y', \n",
    "                               kernel_initializer = tf.contrib.layers.xavier_initializer(), reuse=tf.AUTO_REUSE)\n",
    "        fine_x = PS(fine_x, 2, color=False)\n",
    "        fine_y = PS(fine_y, 2, color=False)\n",
    "        \n",
    "        #add coarse, fine flow\n",
    "        flow_x = tf.add(coarse_x, fine_x)\n",
    "        flow_y = tf.add(coarse_y, fine_y)\n",
    "        flow = tf.concat([flow_x, flow_y], axis = 3)\n",
    "        #Warp\n",
    "        out = batch_warp2d(t1, flow)\n",
    "        #print(\"shape:\", t1.shape, flow.shape, out.shape, out)\n",
    "        print(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def train(self, config, load = True):\n",
    "        # setup train/validation data\n",
    "        '''\n",
    "        valid = sorted(glob(os.path.join(self.config.valid.hr_path, \"*.png\")))\n",
    "        shuffle(valid)\n",
    "        \n",
    "        valid_files = valid[0:self.valid_size]\n",
    "        valid = [load_image(valid_file, self.mode) for valid_file in valid_files]\n",
    "        valid_LR = [doresize(xx, [self.input_size,]*2) for xx in valid]\n",
    "        valid_HR = np.array(valid)\n",
    "        valid_LR = np.array(valid_LR)\n",
    "        if self.mode == \"YCbCr\":\n",
    "            valid_RGB_HR =  np.copy(valid_HR)\n",
    "            valid_HR = np.split(valid_RGB_HR,3, axis=3)[0]\n",
    "            valid_RGB_LR = np.copy(valid_LR)\n",
    "            valid_LR = np.split(valid_RGB_LR,3, axis=3)[0]\n",
    "        '''\n",
    "        counter = 1\n",
    "        start_time = time.time()\n",
    "        if load == True:\n",
    "            if self.load(self.checkpoint_dir):\n",
    "                print(\" [*] Load SUCCESS\")\n",
    "            else:\n",
    "                print(\" [!] Load failed...\")\n",
    "        else:\n",
    "            print(\" Training starts from beginning\")\n",
    "\n",
    "        for epoch in range(self.config.epoch):\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Loading videos again...\")\n",
    "                self.imdb = []\n",
    "                self.num_frames_per_video = []\n",
    "                self.imdb, self.num_frames_per_video = load_videos(30, self.num_videos, 50, self.mode)\n",
    "            batch_idxs = min(len(self.imdb), self.config.train_size) // self.config.batch_size\n",
    "\n",
    "            #for idx in range(0, batch_idxs):\n",
    "            for idx in range(0, 100):\n",
    "                batch_t0, batch_t1 = get_batch_MCT(self.imdb, self.num_frames_per_video, self.batch_size, \n",
    "                                                   [self.input_size, self.input_size], augmentation = self.augmentation)\n",
    "                batch_t0 = np.array(batch_t0)\n",
    "                batch_t1 = np.array(batch_t1)\n",
    "                if self.mode == \"YCbCr\":\n",
    "                    batch_t0 = np.split(batch_t0, 3, axis=3)[0]\n",
    "                    batch_t1 = np.split(batch_t1, 3, axis=3)[0]\n",
    "\n",
    "                _, loss = self.sess.run([self.optimizer, self.loss],\n",
    "                    feed_dict={ self.input_t0: batch_t0, self.input_t1: batch_t1 })\n",
    "\n",
    "                counter+=1\n",
    "                if idx % 500 == 1 and epoch % 100 == 0:\n",
    "                    #print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" %(epoch, idx, batch_idxs, time.time() - start_time, loss))\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, loss: %.8f\" %(epoch, idx, 100, time.time() - start_time, loss))\n",
    "                    self.save(self.config.checkpoint_dir)\n",
    "             \n",
    "            # occasional testing\n",
    "            if epoch % 100 == 0:\n",
    "                avg_PSNR = self.test(load = False)\n",
    "                print(\"Epoch: [%2d] test PSNR: %.6f\" % (epoch, avg_PSNR))\n",
    "        self.save(self.config.checkpoint_dir)\n",
    "    \n",
    "    def test(self, name = \"calendar\", load = True):\n",
    "        result_dir = os.path.join(\"./samples_MCT/\",str(name))\n",
    "        if not os.path.exists(result_dir):\n",
    "            os.makedirs(result_dir)\n",
    "        img_list = sorted(glob(os.path.join(\"/home/johnyi/deeplearning/research/VSR_Datasets/test/\",str(name),\"*.png\")))\n",
    "        \n",
    "        if load == True:\n",
    "            if self.load(self.checkpoint_dir):\n",
    "                print(\" [*] Load SUCCESS\")\n",
    "            else:\n",
    "                print(\" [!] Load failed...\")\n",
    "        avg_PSNR = 0\n",
    "        xx = sorted(glob(os.path.join(\"/home/johnyi/deeplearning/research/VSR_Datasets/test/vid4\", \"*.png\")))\n",
    "        frame_t0 = scipy.misc.imread(\"/home/johnyi/deeplearning/research/VSR_Datasets/test/vid4/calendar/001.png\", mode = self.mode)\n",
    "        frame_t1 = scipy.misc.imread(\"/home/johnyi/deeplearning/research/VSR_Datasets/test/vid4/calendar/002.png\", mode = self.mode)\n",
    "        if self.mode == \"YCbCr\":\n",
    "            frame_t0 = np.split(frame_t0, 3, axis=2)[0]\n",
    "            frame_t1 = np.split(frame_t1, 3, axis=2)[0]\n",
    "        out = self.sess.run([self.output2],\n",
    "                    feed_dict={ self.input2_t0: [frame_t0], self.input2_t1:[frame_t1] })\n",
    "        PSNR_original = calc_PSNR(frame_t0, frame_t1)\n",
    "        imageio.imwrite(result_dir+\"/original_0.png\", frame_t0)\n",
    "        imageio.imwrite(result_dir+\"/original_1.png\", frame_t1)\n",
    "        imageio.imwrite(result_dir+\"/compensated_0.png\", np.squeeze(out[0]))\n",
    "        PSNR_MCT = calc_PSNR(frame_t0, out[0][0,:,:,:])\n",
    "        print(\"PSNR original:\", PSNR_original, \"MCT: \", PSNR_MCT)\n",
    "        return avg_PSNR\n",
    "    \n",
    "    def save(self, checkpoint_dir):\n",
    "        model_name = \"MCT-\"+str(self.mode)\n",
    "        model_dir = \"%s\" % (self.dataset_name)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        self.saver.save(self.sess, os.path.join(checkpoint_dir, model_name))\n",
    "\n",
    "    def load(self, checkpoint_dir):\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        model_dir = \"%s\"% (self.dataset_name)\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        print(\"loading from \",checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            model_name = \"MCT-\"+str(self.mode)+\"-x\"+str(self.scale)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, model_name))\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_14:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"Reshape_29:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Number of variables in network: 28 , full list: [<tf.Variable 'Coarse_1/kernel:0' shape=(5, 5, 6, 24) dtype=float32_ref>, <tf.Variable 'Coarse_1/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Coarse_2/kernel:0' shape=(3, 3, 24, 24) dtype=float32_ref>, <tf.Variable 'Coarse_2/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Coarse_3/kernel:0' shape=(5, 5, 24, 24) dtype=float32_ref>, <tf.Variable 'Coarse_3/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Coarse_4/kernel:0' shape=(3, 3, 24, 24) dtype=float32_ref>, <tf.Variable 'Coarse_4/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Coarse_5/kernel:0' shape=(3, 3, 24, 32) dtype=float32_ref>, <tf.Variable 'Coarse_5/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'Coarse_x/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'Coarse_x/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Coarse_y/kernel:0' shape=(3, 3, 32, 16) dtype=float32_ref>, <tf.Variable 'Coarse_y/bias:0' shape=(16,) dtype=float32_ref>, <tf.Variable 'Fine_1/kernel:0' shape=(5, 5, 6, 24) dtype=float32_ref>, <tf.Variable 'Fine_1/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Fine_2/kernel:0' shape=(3, 3, 24, 24) dtype=float32_ref>, <tf.Variable 'Fine_2/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Fine_3/kernel:0' shape=(3, 3, 24, 24) dtype=float32_ref>, <tf.Variable 'Fine_3/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Fine_4/kernel:0' shape=(3, 3, 24, 24) dtype=float32_ref>, <tf.Variable 'Fine_4/bias:0' shape=(24,) dtype=float32_ref>, <tf.Variable 'Fine_5/kernel:0' shape=(3, 3, 24, 8) dtype=float32_ref>, <tf.Variable 'Fine_5/bias:0' shape=(8,) dtype=float32_ref>, <tf.Variable 'Fine_x/kernel:0' shape=(3, 3, 8, 4) dtype=float32_ref>, <tf.Variable 'Fine_x/bias:0' shape=(4,) dtype=float32_ref>, <tf.Variable 'Fine_y/kernel:0' shape=(3, 3, 8, 4) dtype=float32_ref>, <tf.Variable 'Fine_y/bias:0' shape=(4,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "MCT = MotionCompensationTransformer(sess, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training starts from beginning\n",
      "Loading videos again...\n",
      "loaded video indexes: [73, 17, 48, 11, 51, 0, 28, 66, 14, 41, 32, 7, 50, 18, 20, 8, 25, 58, 42, 26, 62, 54, 13, 23, 64, 69, 46, 22, 49, 15] num_frames per video: 50 runtime:  76.38733911514282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] [   1/ 100] time: 81.1488, loss: 16282.41796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:213: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:214: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/johnyi/.local/lib/python3.5/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float32 to uint8, range [-40.39149856567383, 336.1759948730469]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR original: 18.480092851641135 MCT:  13.22803646817676\n",
      "Epoch: [ 0] test PSNR: 0.000000\n",
      "Loading videos again...\n",
      "loaded video indexes: [50, 15, 57, 33, 20, 39, 11, 68, 75, 12, 53, 60, 19, 23, 13, 1, 41, 70, 45, 8, 66, 27, 2, 22, 4, 47, 74, 5, 36, 16] num_frames per video: 50 runtime:  83.97659087181091\n",
      "Epoch: [100] [   1/ 100] time: 225.3637, loss: 61.19231796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnyi/.local/lib/python3.5/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float32 to uint8, range [-85.7486343383789, 342.98028564453125]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR original: 18.480092851641135 MCT:  21.106966172511868\n",
      "Epoch: [100] test PSNR: 0.000000\n",
      "Loading videos again...\n",
      "loaded video indexes: [33, 60, 42, 71, 70, 1, 25, 14, 20, 40, 2, 55, 8, 3, 17, 4, 30, 50, 43, 21, 64, 63, 72, 39, 68, 0, 47, 66, 31, 51] num_frames per video: 50 runtime:  78.47426629066467\n",
      "Epoch: [200] [   1/ 100] time: 364.8360, loss: 57.20231247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnyi/.local/lib/python3.5/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float32 to uint8, range [-68.81475830078125, 343.2763977050781]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR original: 18.480092851641135 MCT:  22.5350557477666\n",
      "Epoch: [200] test PSNR: 0.000000\n",
      "Loading videos again...\n",
      "loaded video indexes: [61, 36, 62, 63, 45, 74, 30, 5, 73, 20, 41, 13, 23, 3, 51, 24, 14, 52, 50, 57, 35, 11, 75, 46, 71, 68, 54, 28, 64, 43] num_frames per video: 50 runtime:  73.54035830497742\n",
      "Epoch: [300] [   1/ 100] time: 498.1088, loss: 36.39022064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnyi/.local/lib/python3.5/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float32 to uint8, range [-79.45310974121094, 322.7713928222656]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR original: 18.480092851641135 MCT:  23.21801573015413\n",
      "Epoch: [300] test PSNR: 0.000000\n",
      "Loading videos again...\n",
      "loaded video indexes: [57, 37, 48, 71, 9, 38, 58, 5, 19, 8, 66, 10, 68, 36, 69, 43, 50, 51, 49, 64, 61, 59, 72, 3, 73, 23, 14, 31, 13, 47] num_frames per video: 50 runtime:  74.97953581809998\n",
      "Epoch: [400] [   1/ 100] time: 632.3898, loss: 4.58948565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnyi/.local/lib/python3.5/site-packages/imageio/core/util.py:104: UserWarning: Conversion from float32 to uint8, range [-79.02924346923828, 326.2144470214844]\n",
      "  'range [{2}, {3}]'.format(dtype_str, out_type.__name__, mi, ma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR original: 18.480092851641135 MCT:  23.82413472657514\n",
      "Epoch: [400] test PSNR: 0.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3cc859d21cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mMCT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-e1a800aa329e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, config, load)\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 batch_t0, batch_t1 = get_batch_MCT(self.imdb, self.num_frames_per_video, self.batch_size, \n\u001b[0;32m--> 178\u001b[0;31m                                                    [self.input_size, self.input_size], augmentation = self.augmentation)\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mbatch_t0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mbatch_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f24b0d467d04>\u001b[0m in \u001b[0;36mget_batch_MCT\u001b[0;34m(imdb, num_frames_per_video, batch_size, patch_size, augmentation)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpatch_t0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_t0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bicubic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpatch_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresize_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mresize_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpatch_t1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_t1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bicubic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mbatch_t0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_t0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mbatch_t1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_t1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lanczos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m     \u001b[0mimnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m     def rotate(self, angle, resample=NEAREST, expand=0, center=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_new\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    MCT.train(config, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    start_time = time.time()\n",
    "    a,b = espcn.test(name = \"Set5\", load = True)\n",
    "    print(time.time()-start_time)\n",
    "    print(\"avg:\",a,\"bicubic:\",b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
